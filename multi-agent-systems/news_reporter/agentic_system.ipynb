{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Reporter Agentic System Using Semantic Kernel SDK and Azure AI Agent Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install semantic-kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-projects azure-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing important libraries and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "import os\n",
    "import asyncio\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import BingGroundingTool\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_foundry_endpoint = os.getenv(\"AZURE_AI_FOUNDRY_ENDPOINT_PORTAL\")\n",
    "azure_openai_key = os.getenv(\"AZURE_AI_FOUNDRY_OPENAI_KEY\")\n",
    "azure_openai_deployment_name = os.getenv(\"AZURE_AI_FOUNDRY_OPENAI_DEPLOYMENT\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_AI_FOUNDRY_OPENAI_ENDPOINT\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_AI_FOUNDRY_OPENAI_API_VERSION\")\n",
    "bing_connection_name = os.getenv(\"BING_CONNECTION_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=azure_ai_foundry_endpoint,\n",
    "    credential=DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, ID: asst_oUfc1paPsPEkqaEF8AYKAdLH\n"
     ]
    }
   ],
   "source": [
    "with AIProjectClient(\n",
    "    endpoint=azure_ai_foundry_endpoint,\n",
    "    credential=DefaultAzureCredential()\n",
    ") as client:\n",
    "    bing_connection = client.connections.get(\n",
    "        name=bing_connection_name\n",
    "    )\n",
    "    conn_id = bing_connection.id  # Get the connection ID from the Bing connection\n",
    "\n",
    "    # Initialize the Bing Grounding tool\n",
    "    bing = BingGroundingTool(connection_id=conn_id)\n",
    "\n",
    "    agent = client.agents.create_agent(\n",
    "        model=azure_openai_deployment_name,  # Model deployment name\n",
    "        name=\"bing-ai-assistant\",  # Name of the agent\n",
    "        instructions=\"You are a helpful agent\",  # Instructions for the agent\n",
    "        tools=bing.definitions,  # Attach the Bing Grounding tool\n",
    "    )\n",
    "    print(f\"Created agent, ID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, ID: thread_9oPwADQVtiBu0BfTKW9X2bs6\n",
      "Created message, ID: msg_JKObgovpTHxkgcPy4KMHbd4E\n",
      "Created message, ID: msg_JKObgovpTHxkgcPy4KMHbd4E\n"
     ]
    }
   ],
   "source": [
    "# Create a thread for communication\n",
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Add a message to the thread\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",  # Role of the message sender\n",
    "    content=\"What is the weather in Seattle today?\",  # Message content\n",
    ")\n",
    "print(f\"Created message, ID: {message['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished with status: RunStatus.COMPLETED\n",
      "Role: MessageRole.AGENT, Content: [{'type': 'text', 'text': {'value': \"Today's weather in Seattle, WA, includes a high of approximately 82°F (28°C) and a low of about 64°F (18°C), with generally clear skies【3:2†source】.\", 'annotations': [{'type': 'url_citation', 'text': '【3:2†source】', 'start_index': 135, 'end_index': 147, 'url_citation': {'url': 'https://www.accuweather.com/en/us/seattle/98104/august-weather/351409', 'title': 'Seattle, WA Monthly Weather | AccuWeather'}}]}}]\n",
      "Role: MessageRole.USER, Content: [{'type': 'text', 'text': {'value': 'What is the weather in Seattle today?', 'annotations': []}}]\n",
      "Role: MessageRole.AGENT, Content: [{'type': 'text', 'text': {'value': \"Today's weather in Seattle, WA, includes a high of approximately 82°F (28°C) and a low of about 64°F (18°C), with generally clear skies【3:2†source】.\", 'annotations': [{'type': 'url_citation', 'text': '【3:2†source】', 'start_index': 135, 'end_index': 147, 'url_citation': {'url': 'https://www.accuweather.com/en/us/seattle/98104/august-weather/351409', 'title': 'Seattle, WA Monthly Weather | AccuWeather'}}]}}]\n",
      "Role: MessageRole.USER, Content: [{'type': 'text', 'text': {'value': 'What is the weather in Seattle today?', 'annotations': []}}]\n"
     ]
    }
   ],
   "source": [
    "# Create and process an agent run\n",
    "run = project_client.agents.runs.create_and_process(\n",
    "    thread_id=thread.id,\n",
    "    agent_id=agent.id,\n",
    "    # tool_choice={\"type\": \"bing_grounding\"}  # optional, you can force the model to use Grounding with Bing Search tool\n",
    ")\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "# Check if the run failed\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Fetch and log all messages\n",
    "messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "for message in messages:\n",
    "    print(f\"Role: {message.role}, Content: {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an \"Agent\" Plugin Class which will include native plugins to be fed into the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agents:\n",
    "    @kernel_function(\n",
    "        description=\"This function will be used to use an azure ai agent with web grounding capability using Bing Search API\",\n",
    "        name=\"WebSearchAgent\"\n",
    "    )\n",
    "    def web_search_agent(\n",
    "        self,\n",
    "        query: Annotated[str, \"The user query for which the contextual information needs to be fetched from the web\"]\n",
    "        \n",
    "    ) -> Annotated[str, \"The response from the web search agent\"]:\n",
    "        bing_connection = project_client.connections.get(name=bing_connection_name)\n",
    "        conn_id = bing_connection.id\n",
    "        bing = BingGroundingTool(connection_id=conn_id)\n",
    "        \n",
    "        agent = project_client.agents.create_agent(\n",
    "            model=azure_openai_deployment_name,\n",
    "            name=\"bing-assistant\",\n",
    "            instructions=\"You are a helpful assistant\",\n",
    "            tools=bing.definitions\n",
    "        )\n",
    "        thread = project_client.agents.threads.create()\n",
    "    \n",
    "\n",
    "        message = project_client.agents.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=query,\n",
    "        )\n",
    "\n",
    "        run = project_client.agents.runs.create_and_process(\n",
    "            thread_id=thread.id,\n",
    "            agent_id=agent.id,\n",
    "        )\n",
    "\n",
    "        messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "        \n",
    "        for message in messages:\n",
    "            print(f\"Role: {message.role}, Content: {message.content}\")\n",
    "        # Return the content of the first message as the response\n",
    "        return messages[0].content if messages else \"\"\n",
    "    \n",
    "    \n",
    "    @kernel_function(\n",
    "       description=\"This function will use an azure ai agent to prepare a script for a news reporter based on latest information for a specific topic\",\n",
    "         name=\"NewsReporterAgent\"\n",
    "   )\n",
    "    def news_reporter_agent(\n",
    "        self,\n",
    "        topic: Annotated[str, \"The topic for which the latest information/news has been fetched\"],\n",
    "        latest_news: Annotated[str,\"The latest information for a specific topic\"]\n",
    "    ) -> Annotated[str, \"the response from the NewsReporterAgent which is the script for a news reporter\"]:\n",
    "\n",
    "        agent = project_client.agents.create_agent(\n",
    "        model=azure_openai_deployment_name,\n",
    "        name=\"news-reporter\",\n",
    "        instructions=\"\"\"You are a helpful assistant that is meant to prepare a script for a news reporter based on the latest information for a specific topic both of which you will be given.\n",
    "            The news channel is named MSinghTV and the news reporter is named John. You will be given the topic and the latest information for that topic. Prepare a script for the news reporter John based on the latest information for the topic.\"\"\",\n",
    "        )\n",
    "        thread = project_client.agents.threads.create()\n",
    "            \n",
    "        message = project_client.agents.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=f\"\"\"The topic is {topic} and the latest information is {latest_news}\"\"\",\n",
    "            )\n",
    "            \n",
    "        run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "     \n",
    "        messages = project_client.agents.messages.list(thread_id=thread.id)\n",
    "        \n",
    "        print(\"Script for the news reporter:\")\n",
    "        print(\"\\n\")    \n",
    "        for message in messages:\n",
    "            print(f\"Role: {message.role}, Content: {message.content}\")\n",
    "        # Return the content of the first message as the response\n",
    "        return messages[0].content if messages else \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Kernel of the Semantic Kernel SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel()\n",
    "\n",
    "chat_completion = AzureChatCompletion(\n",
    "        api_key=azure_openai_key,\n",
    "        deployment_name=azure_openai_deployment_name,\n",
    "        endpoint=azure_openai_endpoint,\n",
    "        api_version=azure_openai_api_version\n",
    "    )\n",
    "\n",
    "kernel.add_service(\n",
    "    chat_completion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the Agentic Plugins as native plugins to our Kernel so created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_plugin = kernel.add_plugin(Agents(), \"Agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings \n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "# Enable planning\n",
    "execution_settings = AzureChatPromptExecutionSettings()\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a history of the conversation\n",
    "history = ChatHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant > Could you let me know the topic or type of news you want me to prepare the script for John?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function failed. Error: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already.\n",
      "Error invoking function Agents-WebSearchAgent: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already..\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\kernel.py\", line 454, in _inner_auto_function_invoke_handler\n",
      "    result = await context.function.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function.py\", line 259, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function.py\", line 251, in invoke\n",
      "    await stack(function_context)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function_from_method.py\", line 103, in _invoke_internal\n",
      "    result = self.method(**function_arguments)\n",
      "  File \"C:\\Users\\dilmurodm\\AppData\\Local\\Temp\\ipykernel_16828\\1165682953.py\", line 11, in web_search_agent\n",
      "    bing_connection = project_client.connections.get(name=bing_connection_name)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py\", line 119, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_patch_connections.py\", line 42, in get\n",
      "    return super()._get(name, **kwargs)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py\", line 119, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_operations.py\", line 525, in _get\n",
      "    pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access\n",
      "                                          ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        _request, stream=_stream, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 242, in run\n",
      "    return first_node.send(pipeline_request)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py\", line 205, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py\", line 545, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_authentication.py\", line 159, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 130, in send\n",
      "    self._sender.send(request.http_request, **request.context.options),\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 350, in send\n",
      "    self.open()\n",
      "    ~~~~~~~~~^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 287, in open\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already.\n",
      "Error invoking function Agents-WebSearchAgent: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already..\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\kernel.py\", line 454, in _inner_auto_function_invoke_handler\n",
      "    result = await context.function.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function.py\", line 259, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function.py\", line 251, in invoke\n",
      "    await stack(function_context)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function_from_method.py\", line 103, in _invoke_internal\n",
      "    result = self.method(**function_arguments)\n",
      "  File \"C:\\Users\\dilmurodm\\AppData\\Local\\Temp\\ipykernel_16828\\1165682953.py\", line 11, in web_search_agent\n",
      "    bing_connection = project_client.connections.get(name=bing_connection_name)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py\", line 119, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_patch_connections.py\", line 42, in get\n",
      "    return super()._get(name, **kwargs)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py\", line 119, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_operations.py\", line 525, in _get\n",
      "    pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access\n",
      "                                          ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        _request, stream=_stream, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 242, in run\n",
      "    return first_node.send(pipeline_request)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py\", line 205, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py\", line 545, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_authentication.py\", line 159, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 130, in send\n",
      "    self._sender.send(request.http_request, **request.context.options),\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 350, in send\n",
      "    self.open()\n",
      "    ~~~~~~~~~^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 287, in open\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already.\n",
      "Function failed. Error: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already.\n",
      "Error invoking function Agents-WebSearchAgent: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already..\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\kernel.py\", line 454, in _inner_auto_function_invoke_handler\n",
      "    result = await context.function.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function.py\", line 259, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function.py\", line 251, in invoke\n",
      "    await stack(function_context)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function_from_method.py\", line 103, in _invoke_internal\n",
      "    result = self.method(**function_arguments)\n",
      "  File \"C:\\Users\\dilmurodm\\AppData\\Local\\Temp\\ipykernel_16828\\1165682953.py\", line 11, in web_search_agent\n",
      "    bing_connection = project_client.connections.get(name=bing_connection_name)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py\", line 119, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_patch_connections.py\", line 42, in get\n",
      "    return super()._get(name, **kwargs)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py\", line 119, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_operations.py\", line 525, in _get\n",
      "    pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access\n",
      "                                          ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        _request, stream=_stream, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 242, in run\n",
      "    return first_node.send(pipeline_request)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py\", line 205, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py\", line 545, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_authentication.py\", line 159, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 130, in send\n",
      "    self._sender.send(request.http_request, **request.context.options),\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 350, in send\n",
      "    self.open()\n",
      "    ~~~~~~~~~^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 287, in open\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already.\n",
      "Function failed. Error: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already.\n",
      "Error invoking function Agents-WebSearchAgent: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already..\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\kernel.py\", line 454, in _inner_auto_function_invoke_handler\n",
      "    result = await context.function.invoke(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function.py\", line 259, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function.py\", line 251, in invoke\n",
      "    await stack(function_context)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\semantic_kernel\\functions\\kernel_function_from_method.py\", line 103, in _invoke_internal\n",
      "    result = self.method(**function_arguments)\n",
      "  File \"C:\\Users\\dilmurodm\\AppData\\Local\\Temp\\ipykernel_16828\\1165682953.py\", line 11, in web_search_agent\n",
      "    bing_connection = project_client.connections.get(name=bing_connection_name)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py\", line 119, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_patch_connections.py\", line 42, in get\n",
      "    return super()._get(name, **kwargs)\n",
      "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py\", line 119, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_operations.py\", line 525, in _get\n",
      "    pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access\n",
      "                                          ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        _request, stream=_stream, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 242, in run\n",
      "    return first_node.send(pipeline_request)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py\", line 205, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_retry.py\", line 545, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\policies\\_authentication.py\", line 159, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 98, in send\n",
      "    response = self.next.send(request)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 130, in send\n",
      "    self._sender.send(request.http_request, **request.context.options),\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 350, in send\n",
      "    self.open()\n",
      "    ~~~~~~~~~^^\n",
      "  File \"c:\\Users\\dilmurodm\\Desktop\\Semantic_Kernel\\semantic_kernel\\venv_py313\\Lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 287, in open\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant > It seems there’s an issue with fetching the latest news directly. Could you provide more details about the Trump tariffs you are interested in, or I can try another way to gather the latest information for you?\n"
     ]
    }
   ],
   "source": [
    "userInput = None\n",
    "while True:\n",
    "        # Collect user input\n",
    "        userInput = input(\"User > \")\n",
    "\n",
    "        # Terminate the loop if the user says \"exit\"\n",
    "        if userInput == \"exit\":\n",
    "            break\n",
    "\n",
    "        # Add user input to the history\n",
    "        history.add_user_message(userInput)\n",
    "\n",
    "        # 3. Get the response from the AI with automatic function calling\n",
    "        result = await chat_completion.get_chat_message_content(\n",
    "            chat_history=history,\n",
    "            settings=execution_settings,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(\"Assistant > \" + str(result))\n",
    "\n",
    "        # Add the message from the agent to the chat history\n",
    "        history.add_message(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
